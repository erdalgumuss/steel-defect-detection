{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb1d8b7-ee76-4d3e-8617-ca9b1f650425",
   "metadata": {},
   "source": [
    "Notebook â€“ AdÄ±m 1: Ortam & Veri YÃ¼kleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa77e82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Inspect DataLoader\n",
    "- train.csv + train_images okur\n",
    "- Dataset & DataLoader test eder\n",
    "- BirkaÃ§ batch gÃ¶rselleÅŸtirir (orijinal + maskeler + overlay)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from src.data.dataset import SteelDefectDataset, build_full_dataframe\n",
    "from src.data.transforms import get_train_transforms\n",
    "from src.data.rle_decoder import build_multilabel_mask\n",
    "\n",
    "# -----------------------------\n",
    "# YardÄ±mcÄ± fonksiyonlar\n",
    "# -----------------------------\n",
    "def overlay_mask(img, mask, alpha=0.4, color=(1,0,0)):\n",
    "    \"\"\"Tek kanal maskeyi renkli overlay yapar.\"\"\"\n",
    "    img = img.copy()\n",
    "    mask_bool = mask.astype(bool)\n",
    "    img[mask_bool] = (1 - alpha) * img[mask_bool] + alpha * np.array(color)\n",
    "    return img\n",
    "\n",
    "def visualize_batch(images, masks, metas, max_items=2):\n",
    "    \"\"\"\n",
    "    Batch gÃ¶rselleÅŸtir.\n",
    "    images: (B,3,H,W), masks: (B,C,H,W)\n",
    "    \"\"\"\n",
    "    B = min(images.shape[0], max_items)\n",
    "    for i in range(B):\n",
    "        img = images[i].permute(1,2,0).cpu().numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "\n",
    "        mask = masks[i].cpu().numpy()\n",
    "\n",
    "        fig, axes = plt.subplots(1, mask.shape[0] + 2, figsize=(18,5))\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title(f\"Image {i}\\n{metas[i]['image_id']}\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        for c in range(mask.shape[0]):\n",
    "            axes[c+1].imshow(mask[c], cmap=\"gray\")\n",
    "            axes[c+1].set_title(f\"Class {c+1}\\nNonzero={mask[c].sum()}\")\n",
    "            axes[c+1].axis(\"off\")\n",
    "\n",
    "        # overlay Ã¶rneÄŸi (sadece Class 1)\n",
    "        overlay = overlay_mask(img, mask[0], alpha=0.5, color=(1,0,0))\n",
    "        axes[-1].imshow(overlay)\n",
    "        axes[-1].set_title(\"Overlay (Class 1)\")\n",
    "        axes[-1].axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Ana script\n",
    "# -----------------------------\n",
    "def main():\n",
    "    train_csv = \"data/raw/train.csv\"\n",
    "    train_images_dir = \"data/raw/train_images\"\n",
    "    \n",
    "    train_df = pd.read_csv(train_csv)   # ðŸ‘ˆ Ã¶nce CSVâ€™yi oku\n",
    "\n",
    "    df = build_full_dataframe(train_df, train_images_dir)\n",
    "\n",
    "    dataset = SteelDefectDataset(\n",
    "        df, \n",
    "        train_images_dir,\n",
    "        transforms=get_train_transforms()\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        collate_fn=lambda x: (\n",
    "            torch.stack([i[0] for i in x]),\n",
    "            torch.stack([i[1] for i in x]),\n",
    "            [i[2] for i in x]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    images, masks, metas = next(iter(loader))\n",
    "    print(\"Batch image shape:\", images.shape)\n",
    "    print(\"Batch mask shape:\", masks.shape)\n",
    "    print(\"Meta Ã¶rnek:\", metas[0])\n",
    "\n",
    "    visualize_batch(images, masks, metas, max_items=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb3f43-0e55-4363-841b-c6b6fb3fb75f",
   "metadata": {},
   "source": [
    "Notebook â€“ AdÄ±m 2: Veri KeÅŸfi (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0da62078-d851-4379-9b56-5f714b98b368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7095 entries, 0 to 7094\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ImageId        7095 non-null   object\n",
      " 1   ClassId        7095 non-null   int64 \n",
      " 2   EncodedPixels  7095 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 166.4+ KB\n",
      "None\n",
      "SÄ±nÄ±flar: [1 3 4 2]\n",
      "SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\n",
      " ClassId\n",
      "3    5150\n",
      "1     897\n",
      "4     801\n",
      "2     247\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kusursuz satÄ±r sayÄ±sÄ±: 0\n"
     ]
    }
   ],
   "source": [
    "# Genel bilgi\n",
    "print(train_df.info())\n",
    "\n",
    "# KaÃ§ farklÄ± sÄ±nÄ±f var?\n",
    "print(\"SÄ±nÄ±flar:\", train_df['ClassId'].unique())\n",
    "\n",
    "# SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±\n",
    "print(\"SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\\n\", train_df['ClassId'].value_counts())\n",
    "\n",
    "# HatasÄ±z gÃ¶rÃ¼ntÃ¼ (EncodedPixels = NaN)\n",
    "num_no_defect = train_df['EncodedPixels'].isnull().sum()\n",
    "print(f\"\\nKusursuz satÄ±r sayÄ±sÄ±: {num_no_defect}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61f9c0a0-b707-41bf-9779-ef1ec87b7a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam 12568 gÃ¶rÃ¼ntÃ¼ bulundu.\n",
      "BirleÅŸik df boyutu: (12997, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5facf38ab.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e9055d9e.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124667 3 124918 8 125081 14 125169 13 125319 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0eb3a086.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>117641 30 117897 90 118153 120 118409 120 1186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578e97b72.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3a14b011a.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87130 28 87342 86 87573 125 87828 140 88083 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  ClassId                                      EncodedPixels\n",
       "0  5facf38ab.jpg      NaN                                                NaN\n",
       "1  4e9055d9e.jpg      1.0  124667 3 124918 8 125081 14 125169 13 125319 4...\n",
       "2  c0eb3a086.jpg      2.0  117641 30 117897 90 118153 120 118409 120 1186...\n",
       "3  578e97b72.jpg      NaN                                                NaN\n",
       "4  3a14b011a.jpg      3.0  87130 28 87342 86 87573 125 87828 140 88083 15..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GÃ¶rsellerin varlÄ±ÄŸÄ±nÄ± kontrol et\n",
    "all_image_paths = glob(os.path.join(train_images_dir, \"*.jpg\"))\n",
    "print(f\"Toplam {len(all_image_paths)} gÃ¶rÃ¼ntÃ¼ bulundu.\")\n",
    "\n",
    "# Dosya adlarÄ±yla df oluÅŸtur\n",
    "all_image_ids = [os.path.basename(p) for p in all_image_paths]\n",
    "all_images_df = pd.DataFrame(all_image_ids, columns=[\"ImageId\"])\n",
    "\n",
    "# train.csv ile birleÅŸtir\n",
    "full_df = all_images_df.merge(train_df, on=\"ImageId\", how=\"left\")\n",
    "\n",
    "print(\"BirleÅŸik df boyutu:\", full_df.shape)\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4ee91-1461-4585-a79c-d8fa43621052",
   "metadata": {},
   "source": [
    "Notebook â€“ AdÄ±m 3: RLE â†’ Maske Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5051726-ee2d-4b33-afa1-cd6260e2f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: torch.Size([2, 3, 256, 1600])\n",
      "Masks: torch.Size([2, 4, 256, 1600])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages:\u001b[39m\u001b[38;5;124m\"\u001b[39m, images\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# [B, 3, H, W]\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasks:\u001b[39m\u001b[38;5;124m\"\u001b[39m, masks\u001b[38;5;241m.\u001b[39mshape)    \u001b[38;5;66;03m# [B, 4, H, W]\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta sample:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmetas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# --- Ã–rnek gÃ¶rselleÅŸtirme ---\u001b[39;00m\n\u001b[1;32m     36\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from src.data.rle_decoder import rle_to_mask, build_multilabel_mask\n",
    "from src.data.dataset import SteelDefectDataset, build_full_dataframe\n",
    "from src.data.transforms import get_valid_transforms\n",
    "\n",
    "# --- Config ---\n",
    "csv_path = \"/app/data/raw/train.csv\"\n",
    "image_dir = \"/app/data/raw/train_images\"\n",
    "H, W = 256, 1600\n",
    "\n",
    "# --- CSV yÃ¼kle ---\n",
    "train_df = pd.read_csv(csv_path)\n",
    "full_df = build_full_dataframe(train_df, image_dir)\n",
    "\n",
    "# --- Dataset ve Loader ---\n",
    "ds = SteelDefectDataset(\n",
    "    df=full_df,\n",
    "    image_dir=image_dir,\n",
    "    num_classes=4,\n",
    "    transforms=get_valid_transforms(H, W)\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=2, shuffle=True)\n",
    "\n",
    "# --- Bir batch Ã§ekelim ---\n",
    "images, masks, metas = next(iter(loader))\n",
    "\n",
    "print(\"Images:\", images.shape)  # [B, 3, H, W]\n",
    "print(\"Masks:\", masks.shape)    # [B, 4, H, W]\n",
    "print(\"Meta sample:\", metas[0])\n",
    "\n",
    "# --- Ã–rnek gÃ¶rselleÅŸtirme ---\n",
    "idx = 0\n",
    "img = images[idx].permute(1,2,0).cpu().numpy()\n",
    "mask = masks[idx].cpu().numpy()  # (4, H, W)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "axes[0].imshow(img.astype(\"uint8\"))\n",
    "axes[0].set_title(\"Image\")\n",
    "\n",
    "for c in range(4):\n",
    "    axes[c+1].imshow(mask[c], cmap=\"gray\")\n",
    "    axes[c+1].set_title(f\"Class {c+1}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- TutarlÄ±lÄ±k kontrolÃ¼ ---\n",
    "sample_id = metas[0][\"image_id\"]\n",
    "rows = full_df[full_df[\"ImageId\"] == sample_id]\n",
    "mask_direct = build_multilabel_mask(rows, shape=(H,W), num_classes=4)\n",
    "\n",
    "print(\"Dataset mask sum:\", masks[0].sum().item())\n",
    "print(\"Direct mask sum:\", mask_direct.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f877a-aff4-4971-b793-10993cc825a6",
   "metadata": {},
   "source": [
    "Tek RLE Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73291530-d640-489e-bc6d-120af9ecb4a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m H, W \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m1600\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# --- CSV yÃ¼kle ---\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m full_df \u001b[38;5;241m=\u001b[39m build_full_dataframe(train_df, image_dir)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# --- Dataset ve Loader ---\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/train.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from src.data.rle_decoder import rle_to_mask, build_multilabel_mask\n",
    "from src.data.dataset import SteelDefectDataset, build_full_dataframe\n",
    "from src.data.transforms import get_valid_transforms\n",
    "\n",
    "# --- Config ---\n",
    "csv_path = \"data/raw/train.csv\"\n",
    "image_dir = \"data/raw/train_images\"\n",
    "H, W = 256, 1600\n",
    "\n",
    "# --- CSV yÃ¼kle ---\n",
    "train_df = pd.read_csv(csv_path)\n",
    "full_df = build_full_dataframe(train_df, image_dir)\n",
    "\n",
    "# --- Dataset ve Loader ---\n",
    "ds = SteelDefectDataset(\n",
    "    df=full_df,\n",
    "    image_dir=image_dir,\n",
    "    shape=(H, W),\n",
    "    num_classes=4,\n",
    "    transforms=get_valid_transforms(H, W)\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=2, shuffle=True)\n",
    "\n",
    "# --- Bir batch Ã§ekelim ---\n",
    "images, masks, metas = next(iter(loader))\n",
    "\n",
    "print(\"Images:\", images.shape)  # [B, 3, H, W]\n",
    "print(\"Masks:\", masks.shape)    # [B, 4, H, W]\n",
    "print(\"Meta sample:\", metas[0])\n",
    "\n",
    "# --- Ã–rnek gÃ¶rselleÅŸtirme ---\n",
    "idx = 0\n",
    "img = images[idx].permute(1,2,0).cpu().numpy()\n",
    "mask = masks[idx].cpu().numpy()  # (4, H, W)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "axes[0].imshow(img.astype(\"uint8\"))\n",
    "axes[0].set_title(\"Image\")\n",
    "\n",
    "for c in range(4):\n",
    "    axes[c+1].imshow(mask[c], cmap=\"gray\")\n",
    "    axes[c+1].set_title(f\"Class {c+1}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- TutarlÄ±lÄ±k kontrolÃ¼ ---\n",
    "sample_id = metas[0][\"image_id\"]\n",
    "rows = full_df[full_df[\"ImageId\"] == sample_id]\n",
    "mask_direct = build_multilabel_mask(rows, shape=(H,W), num_classes=4)\n",
    "\n",
    "print(\"Dataset mask sum:\", masks[0].sum().item())\n",
    "print(\"Direct mask sum:\", mask_direct.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b653a1-4b0a-4cff-9f70-0b245456ba71",
   "metadata": {},
   "source": [
    "Ã‡ok-kanallÄ± Maske Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e0d351-0253-4ece-8755-c2d02cb109ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_multilabel_mask() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m image_id \u001b[38;5;241m=\u001b[39m full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m rows \u001b[38;5;241m=\u001b[39m full_df[full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m image_id]\n\u001b[0;32m----> 5\u001b[0m multi_mask \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_multilabel_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, multi_mask\u001b[38;5;241m.\u001b[39mshape)   \u001b[38;5;66;03m# (4, H, W)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass pixel sums:\u001b[39m\u001b[38;5;124m\"\u001b[39m, multi_mask\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: build_multilabel_mask() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "# Ã–rnek bir gÃ¶rÃ¼ntÃ¼ al\n",
    "image_id = full_df[\"ImageId\"].iloc[0]\n",
    "rows = full_df[full_df[\"ImageId\"] == image_id]\n",
    "\n",
    "multi_mask = build_multilabel_mask(rows, shape=(256,1600), num_classes=4)\n",
    "print(\"Mask shape:\", multi_mask.shape)   # (4, H, W)\n",
    "print(\"Class pixel sums:\", multi_mask.sum(axis=(1,2)))\n",
    "\n",
    "# Her sÄ±nÄ±fÄ± ayrÄ± gÃ¶rselleÅŸtir\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "for i in range(4):\n",
    "    axs[i].imshow(multi_mask[i], cmap=\"gray\")\n",
    "    axs[i].set_title(f\"Class {i+1}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bededb8-b7ed-4a86-b0fb-5c546233f05a",
   "metadata": {},
   "source": [
    "Ã‡ok-kanallÄ± Maske Testi (Notebook hÃ¼cresi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f241c3-8186-4313-b581-d776a9f2c6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kusurlu gÃ¶rÃ¼ntÃ¼: 4e9055d9e.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e9055d9e.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124667 3 124918 8 125081 14 125169 13 125319 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  ClassId                                      EncodedPixels\n",
       "1  4e9055d9e.jpg      1.0  124667 3 124918 8 125081 14 125169 13 125319 4..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "build_multilabel_mask() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKusurlu gÃ¶rÃ¼ntÃ¼:\u001b[39m\u001b[38;5;124m\"\u001b[39m, defect_id)\n\u001b[1;32m      6\u001b[0m display(rows_defect)\n\u001b[0;32m----> 8\u001b[0m multi_mask_def \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_multilabel_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows_defect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, multi_mask_def\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass pixel sums:\u001b[39m\u001b[38;5;124m\"\u001b[39m, multi_mask_def\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: build_multilabel_mask() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "# Kusurlu bir gÃ¶rÃ¼ntÃ¼ seÃ§elim\n",
    "defect_id = full_df[full_df[\"EncodedPixels\"].notna()][\"ImageId\"].iloc[0]\n",
    "rows_defect = full_df[full_df[\"ImageId\"] == defect_id]\n",
    "\n",
    "print(\"Kusurlu gÃ¶rÃ¼ntÃ¼:\", defect_id)\n",
    "display(rows_defect)\n",
    "\n",
    "multi_mask_def = build_multilabel_mask(rows_defect, shape=(256,1600), num_classes=4)\n",
    "print(\"Mask shape:\", multi_mask_def.shape)\n",
    "print(\"Class pixel sums:\", multi_mask_def.sum(axis=(1,2)))\n",
    "\n",
    "# GÃ¶rselleÅŸtirme\n",
    "fig, axs = plt.subplots(1, 4, figsize=(18, 5))\n",
    "for i in range(4):\n",
    "    axs[i].imshow(multi_mask_def[i], cmap=\"gray\")\n",
    "    axs[i].set_title(f\"Class {i+1}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bc882-4675-414f-8ed3-48298294f94b",
   "metadata": {},
   "source": [
    "Overlay Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2f2ca6f-b38a-496e-806f-208ea544bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def overlay_mask_on_image(image_path: str, mask: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    GÃ¶rÃ¼ntÃ¼ Ã¼zerine 4-kanallÄ± maskeyi renklendirip bindirir.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Orijinal gÃ¶rÃ¼ntÃ¼nÃ¼n yolu.\n",
    "        mask (np.ndarray): (4, H, W) Ã§ok-kanallÄ± maske.\n",
    "        alpha (float): Maske karÄ±ÅŸÄ±m oranÄ± [0-1].\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: RGB formatÄ±nda overlay gÃ¶rÃ¼ntÃ¼.\n",
    "    \"\"\"\n",
    "    # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    assert mask.shape[1:] == (h, w), f\"Mask shape {mask.shape} image shape {(h, w)} ile uyuÅŸmuyor!\"\n",
    "\n",
    "    # Maske kanallarÄ±nÄ± HWCâ€™ye Ã§evir\n",
    "    mask_hwc = np.transpose(mask, (1, 2, 0))  # (H, W, 4)\n",
    "\n",
    "    # Renk paleti (her sÄ±nÄ±f iÃ§in ayrÄ± renk)\n",
    "    color_map = np.array([\n",
    "        [255,   0,   0],   # Class 1 â†’ KÄ±rmÄ±zÄ±\n",
    "        [  0, 255,   0],   # Class 2 â†’ YeÅŸil\n",
    "        [  0,   0, 255],   # Class 3 â†’ Mavi\n",
    "        [255, 255,   0],   # Class 4 â†’ SarÄ±\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "    # Renkli maske Ã¼ret\n",
    "    color_mask = (mask_hwc @ color_map).clip(0, 255).astype(np.uint8)  # (H, W, 3)\n",
    "\n",
    "    # Overlay\n",
    "    overlay = cv2.addWeighted(img, 1.0, color_mask, alpha, 0)\n",
    "    return overlay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29460966-ced1-46cf-803e-141b7ac3946e",
   "metadata": {},
   "source": [
    "ðŸ”¹ Overlay Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7742a5bf-03c1-42fd-a57e-f83a7300ba5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_multilabel_mask() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m defect_id \u001b[38;5;241m=\u001b[39m full_df[full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncodedPixels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m rows_defect \u001b[38;5;241m=\u001b[39m full_df[full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m defect_id]\n\u001b[0;32m----> 4\u001b[0m multi_mask_def \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_multilabel_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows_defect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Orijinal yol\u001b[39;00m\n\u001b[1;32m      7\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_images_dir, defect_id)\n",
      "\u001b[0;31mTypeError\u001b[0m: build_multilabel_mask() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "# Kusurlu bir Ã¶rnek seÃ§elim\n",
    "defect_id = full_df[full_df[\"EncodedPixels\"].notna()][\"ImageId\"].iloc[0]\n",
    "rows_defect = full_df[full_df[\"ImageId\"] == defect_id]\n",
    "multi_mask_def = build_multilabel_mask(rows_defect, shape=(256,1600), num_classes=4)\n",
    "\n",
    "# Orijinal yol\n",
    "img_path = os.path.join(train_images_dir, defect_id)\n",
    "\n",
    "# Overlay uygula\n",
    "overlay_img = overlay_mask_on_image(img_path, multi_mask_def, alpha=0.5)\n",
    "\n",
    "# GÃ¶rselleÅŸtir\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.imshow(overlay_img)\n",
    "plt.title(f\"Overlay: {defect_id}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31368a33-94b2-4faa-affe-0c5092408f8e",
   "metadata": {},
   "source": [
    "Dataset Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683a0dce-c975-4828-8ce2-408da4a6a43f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SteelDefectDataset.__init__() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m full_df \u001b[38;5;241m=\u001b[39m build_full_dataframe(train_df, train_images_dir)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Dataset Ã¶rneÄŸi\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mSteelDefectDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_rgb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset length:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ds))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Ä°lk Ã¶rnek\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: SteelDefectDataset.__init__() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append(\"/app/src\")  # projenin src yolunu ekle (senin docker path'ine gÃ¶re)\n",
    "\n",
    "from data.dataset import SteelDefectDataset, build_full_dataframe\n",
    "\n",
    "# Full df oluÅŸtur\n",
    "full_df = build_full_dataframe(train_df, train_images_dir)\n",
    "\n",
    "# Dataset Ã¶rneÄŸi\n",
    "ds = SteelDefectDataset(full_df, train_images_dir, shape=(256,1600), num_classes=4, load_rgb=True)\n",
    "\n",
    "print(\"Dataset length:\", len(ds))\n",
    "\n",
    "# Ä°lk Ã¶rnek\n",
    "img, mask, meta = ds[0]\n",
    "print(\"Image tensor:\", img.shape, img.dtype)   # (3, H, W), float32\n",
    "print(\"Mask tensor:\", mask.shape, mask.dtype) # (4, H, W), float32\n",
    "print(\"Meta:\", meta)\n",
    "\n",
    "# KÃ¼Ã§Ã¼k DataLoader\n",
    "loader = DataLoader(ds, batch_size=2, shuffle=True)\n",
    "batch = next(iter(loader))\n",
    "print(\"Batch image shape:\", batch[0].shape)\n",
    "print(\"Batch mask shape:\", batch[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772d605-fb34-4dd9-86c9-e88a34db3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import SteelDefectDataset, build_full_dataframe\n",
    "from src.data.transforms import get_train_transforms, get_valid_transforms\n",
    "\n",
    "# Dataset + transform test\n",
    "full_df = build_full_dataframe(train_df, train_images_dir)\n",
    "\n",
    "# EÄŸitim dataset'i (augmentli)\n",
    "train_ds = SteelDefectDataset(full_df, train_images_dir, transforms=get_train_transforms())\n",
    "\n",
    "# Validation dataset'i (sadece resize + normalize)\n",
    "valid_ds = SteelDefectDataset(full_df, train_images_dir, transforms=get_valid_transforms())\n",
    "\n",
    "# Bir Ã¶rnek Ã§ekelim\n",
    "img, mask, meta = train_ds[0]\n",
    "\n",
    "print(\"Image shape:\", img.shape, img.dtype)   # torch.Size([3, H, W])\n",
    "print(\"Mask shape:\", mask.shape, mask.dtype) # torch.Size([4, H, W])\n",
    "\n",
    "# GÃ¶rselleÅŸtirme\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch -> numpy\n",
    "img_np = img.permute(1,2,0).cpu().numpy()\n",
    "mask_np = mask.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow((img_np - img_np.min()) / (img_np.max() - img_np.min()))  # normalize gÃ¶rsellik iÃ§in\n",
    "axs[0].set_title(\"Augmented Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "axs[1].imshow(mask_np[...,0], cmap=\"gray\")  # sadece Class 1\n",
    "axs[1].set_title(\"Augmented Mask (Class 1)\")\n",
    "axs[1].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ff7177d-2817-416c-bb1a-45feb6b538d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeÃ§ilen kusurlu gÃ¶rÃ¼ntÃ¼: e5cc898b6.jpg\n",
      "Image shape: torch.Size([3, 256, 1600])\n",
      "Mask shape: torch.Size([4, 256, 1600])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "build_multilabel_mask() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m orig_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_images_dir, sample_id)\n\u001b[1;32m     36\u001b[0m orig_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(orig_path), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 37\u001b[0m orig_mask \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_multilabel_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n\u001b[1;32m     41\u001b[0m axs[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(orig_img)\n",
      "\u001b[0;31mTypeError\u001b[0m: build_multilabel_mask() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from src.data.dataset import SteelDefectDataset, build_full_dataframe\n",
    "from src.data.transforms import get_train_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Full DataFrame oluÅŸtur\n",
    "full_df = build_full_dataframe(train_df, train_images_dir)\n",
    "\n",
    "# Kusurlu gÃ¶rÃ¼ntÃ¼lerden birini seÃ§elim\n",
    "defect_ids = full_df[full_df[\"EncodedPixels\"].notna()][\"ImageId\"].unique()\n",
    "sample_id = random.choice(defect_ids)\n",
    "rows = full_df[full_df[\"ImageId\"] == sample_id]\n",
    "\n",
    "print(\"SeÃ§ilen kusurlu gÃ¶rÃ¼ntÃ¼:\", sample_id)\n",
    "\n",
    "# Dataset Ã¶rneÄŸi (sadece bu gÃ¶rÃ¼ntÃ¼ ile test etmek iÃ§in kÃ¼Ã§Ã¼k bir df)\n",
    "sample_df = rows.copy()\n",
    "sample_dataset = SteelDefectDataset(sample_df, train_images_dir, transforms=get_train_transforms())\n",
    "\n",
    "# Augmentasyon sonucu gÃ¶rÃ¼ntÃ¼ ve maske al\n",
    "img, mask, meta = sample_dataset[0]\n",
    "\n",
    "print(\"Image shape:\", img.shape)\n",
    "print(\"Mask shape:\", mask.shape)\n",
    "\n",
    "# Torch -> numpy\n",
    "img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "mask_np = mask.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# GÃ¶rselleÅŸtirme: orijinal + augmentli\n",
    "from src.data.rle_decoder import build_multilabel_mask\n",
    "import cv2, os\n",
    "\n",
    "# Orijinal gÃ¶rÃ¼ntÃ¼\n",
    "orig_path = os.path.join(train_images_dir, sample_id)\n",
    "orig_img = cv2.cvtColor(cv2.imread(orig_path), cv2.COLOR_BGR2RGB)\n",
    "orig_mask = build_multilabel_mask(rows, shape=(256,1600))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axs[0,0].imshow(orig_img)\n",
    "axs[0,0].set_title(\"Orijinal GÃ¶rÃ¼ntÃ¼\")\n",
    "axs[0,0].axis(\"off\")\n",
    "\n",
    "axs[0,1].imshow(orig_mask[0], cmap=\"gray\")\n",
    "axs[0,1].set_title(\"Orijinal Maske (Class 1)\")\n",
    "axs[0,1].axis(\"off\")\n",
    "\n",
    "axs[1,0].imshow((img_np - img_np.min()) / (img_np.max() - img_np.min()))\n",
    "axs[1,0].set_title(\"Augmented Image\")\n",
    "axs[1,0].axis(\"off\")\n",
    "\n",
    "axs[1,1].imshow(mask_np[...,0], cmap=\"gray\")\n",
    "axs[1,1].set_title(\"Augmented Mask (Class 1)\")\n",
    "axs[1,1].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f31f71-0bda-4445-8c9d-ebd8e684d06f",
   "metadata": {},
   "source": [
    "â€“ DataLoader Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6cfb3ea-3178-4c6b-b0c7-05ba36a1710c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(images), torch\u001b[38;5;241m.\u001b[39mstack(masks), \u001b[38;5;28mlist\u001b[39m(metas)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# DataLoader\u001b[39;00m\n\u001b[1;32m     11\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mtrain_ds\u001b[49m,\n\u001b[1;32m     13\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     14\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,   \u001b[38;5;66;03m# Notebook iÃ§in gÃ¼venli\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Ä°lk batch\u001b[39;00m\n\u001b[1;32m     20\u001b[0m images, masks, metas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom collate_fn (metas = list of dict)\n",
    "def collate_fn(batch):\n",
    "    images, masks, metas = zip(*batch)\n",
    "    return torch.stack(images), torch.stack(masks), list(metas)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,   # Notebook iÃ§in gÃ¼venli\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Ä°lk batch\n",
    "images, masks, metas = next(iter(train_loader))\n",
    "\n",
    "print(\"Batch image shape:\", images.shape)   # (B, 3, H, W)\n",
    "print(\"Batch mask shape:\", masks.shape)    # (B, 4, H, W)\n",
    "print(\"Meta Ã¶rnek:\", metas[0])             # {'image_id': 'xxx.jpg'}\n",
    "\n",
    "# GÃ¶rselleÅŸtirme\n",
    "for i in range(images.shape[0]):\n",
    "    img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "    mask = masks[i].cpu().numpy()  # (4, H, W)\n",
    "\n",
    "    print(f\"\\nImage {i} ({metas[i]['image_id']}) - Class pixel sums:\", mask.sum(axis=(1,2)))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    axs[0].imshow((img - img.min()) / (img.max() - img.min()))\n",
    "    axs[0].set_title(f\"Image {i}\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    # Her class iÃ§in ayrÄ± plot\n",
    "    for c in range(4):\n",
    "        axs[c+1].imshow(mask[c], cmap=\"gray\")\n",
    "        axs[c+1].set_title(f\"Class {c+1}\")\n",
    "        axs[c+1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e739c76-123f-4b79-af4f-8518fa58917a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m model \u001b[38;5;241m=\u001b[39m UNetResNet18(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# âœ… DataLoader'dan bir batch al\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_ds\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m     63\u001b[0m images, masks, metas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m     64\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), masks\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# âœ… Model kodunu buraya ekliyoruz\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class UNetResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=4, pretrained=True):\n",
    "        super().__init__()\n",
    "        base_model = models.resnet18(weights=\"IMAGENET1K_V1\" if pretrained else None)\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(base_model.conv1, base_model.bn1, base_model.relu)  # (64, H/2, W/2)\n",
    "        self.enc2 = nn.Sequential(base_model.maxpool, base_model.layer1)              # (64, H/4, W/4)\n",
    "        self.enc3 = base_model.layer2                                                # (128, H/8, W/8)\n",
    "        self.enc4 = base_model.layer3                                                # (256, H/16, W/16)\n",
    "        self.enc5 = base_model.layer4                                                # (512, H/32, W/32)\n",
    "\n",
    "        # Decoder\n",
    "        self.up4 = self._up_block(512, 256)\n",
    "        self.up3 = self._up_block(256, 128)\n",
    "        self.up2 = self._up_block(128, 64)\n",
    "        self.up1 = self._up_block(64, 64)\n",
    "\n",
    "        # Son katman\n",
    "        self.final = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "        # Ek upsample â†’ output'u input boyutuna eÅŸitle\n",
    "        self.upsample_out = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    def _up_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        e5 = self.enc5(e4)\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        d4 = self.up4(e5) + e4\n",
    "        d3 = self.up3(d4) + e3\n",
    "        d2 = self.up2(d3) + e2\n",
    "        d1 = self.up1(d2) + e1\n",
    "\n",
    "        out = self.final(d1)          # (B, C, 128, 800)\n",
    "        out = self.upsample_out(out)  # (B, C, 256, 1600)\n",
    "        return out\n",
    "\n",
    "\n",
    "# âœ… Model instance oluÅŸtur\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = UNetResNet18(num_classes=4, pretrained=False).to(device)\n",
    "\n",
    "# âœ… DataLoader'dan bir batch al\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "images, masks, metas = next(iter(train_loader))\n",
    "images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "# âœ… Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "\n",
    "print(\"Input shape :\", images.shape)   # (B, 3, 256, 1600)\n",
    "print(\"Output shape:\", outputs.shape)  # (B, 4, 256, 1600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce5a8d24-5359-4daf-9363-0c9b8ee1952d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m UNetResNet18(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# DataLoader'dan bir batch al\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m images, masks, metas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_loader\u001b[49m))\n\u001b[1;32m     10\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.unet import UNetResNet18\n",
    "\n",
    "# Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = UNetResNet18(num_classes=4, pretrained=False).to(device)\n",
    "\n",
    "# DataLoader'dan bir batch al\n",
    "images, masks, metas = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "\n",
    "print(\"Input shape :\", images.shape)   # (B, 3, 256, 1600)\n",
    "print(\"Output shape:\", outputs.shape)  # (B, 4, 256, 1600)\n",
    "print(\"Meta Ã¶rnek :\", metas[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "513753d7-5213-4a97-98ea-dea4ab46f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Loss : 0.4999915361404419\n",
      "Focal Loss: 0.08664891868829727\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from losses.dice_loss import DiceLoss\n",
    "from losses.focal_loss import FocalLoss\n",
    "\n",
    "# Dummy veri\n",
    "preds = torch.randn(2, 4, 256, 1600)  # logits\n",
    "targets = torch.randint(0, 2, (2, 4, 256, 1600)).float()\n",
    "\n",
    "dice_loss = DiceLoss()\n",
    "focal_loss = FocalLoss()\n",
    "\n",
    "print(\"Dice Loss :\", dice_loss(preds, targets).item())\n",
    "print(\"Focal Loss:\", focal_loss(preds, targets).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4662f37d-c53b-4a38-8a6c-7202b3fdabc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mengines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_one_epoch, validate_one_epoch\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# KÃ¼Ã§Ã¼k subset (Ã¶rnek olarak ilk 8 gÃ¶rÃ¼ntÃ¼)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train_subset \u001b[38;5;241m=\u001b[39m Subset(\u001b[43mtrain_ds\u001b[49m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     10\u001b[0m val_subset   \u001b[38;5;241m=\u001b[39m Subset(train_ds, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     12\u001b[0m train_stats \u001b[38;5;241m=\u001b[39m train_one_epoch(model, train_loader, optimizer, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from models.unet import UNetResNet18\n",
    "from losses.dice_loss import DiceLoss\n",
    "from engines.training_engine import train_one_epoch, validate_one_epoch\n",
    "\n",
    "# KÃ¼Ã§Ã¼k subset (Ã¶rnek olarak ilk 8 gÃ¶rÃ¼ntÃ¼)\n",
    "train_subset = Subset(train_ds, range(8))\n",
    "val_subset   = Subset(train_ds, range(8))\n",
    "\n",
    "train_stats = train_one_epoch(model, train_loader, optimizer, device=device)\n",
    "val_stats   = validate_one_epoch(model, val_loader, device=device)\n",
    "\n",
    "# Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = UNetResNet18(num_classes=4, pretrained=False).to(device)\n",
    "\n",
    "# Loss & Optimizer\n",
    "loss_fn = DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 1 epoch train + validate\n",
    "train_stats = train_one_epoch(model, train_loader, optimizer, device=device)\n",
    "val_stats   = validate_one_epoch(model, val_loader, device=device)\n",
    "\n",
    "print(\"Train stats:\", train_stats)\n",
    "print(\"Val stats  :\", val_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6c13405-a70e-47a3-92b5-9d6593e95a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def dice_coefficient(preds: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Dice Coefficient (F1 Score) for segmentation.\n",
    "    \n",
    "    Args:\n",
    "        preds: (B, C, H, W) logits\n",
    "        targets: (B, C, H, W) binary masks {0,1}\n",
    "        threshold: probability threshold to binarize predictions\n",
    "        eps: numerical stability constant\n",
    "    \"\"\"\n",
    "    # Sigmoid â†’ [0,1]\n",
    "    preds = torch.sigmoid(preds)\n",
    "\n",
    "    # Binarize\n",
    "    preds = (preds > threshold).float()\n",
    "\n",
    "    preds = preds.contiguous().view(preds.size(0), preds.size(1), -1)\n",
    "    targets = targets.contiguous().view(targets.size(0), targets.size(1), -1)\n",
    "\n",
    "    intersection = (preds * targets).sum(dim=2)\n",
    "    denominator = preds.sum(dim=2) + targets.sum(dim=2)\n",
    "\n",
    "    dice = (2.0 * intersection + eps) / (denominator + eps)\n",
    "    return dice.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "455775e1-d902-4905-a19a-3e3bfb20869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient: 0.49970173835754395\n"
     ]
    }
   ],
   "source": [
    "from metrics.dice_coefficient import dice_coefficient\n",
    "import torch\n",
    "\n",
    "# Dummy test\n",
    "preds = torch.randn(2, 4, 256, 1600)   # logits\n",
    "targets = torch.randint(0, 2, (2, 4, 256, 1600)).float()\n",
    "\n",
    "score = dice_coefficient(preds, targets)\n",
    "print(\"Dice Coefficient:\", score.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f69536c-de58-4072-b53e-e8ed03afb53f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Subset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Ä°lk 10 Ã¶rnekle hÄ±zlÄ± test\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m small_train_ds \u001b[38;5;241m=\u001b[39m Subset(\u001b[43mtrain_ds\u001b[49m, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)))\n\u001b[1;32m      5\u001b[0m small_valid_ds \u001b[38;5;241m=\u001b[39m Subset(train_ds, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Ä°lk 10 Ã¶rnekle hÄ±zlÄ± test\n",
    "small_train_ds = Subset(train_ds, list(range(10)))\n",
    "small_valid_ds = Subset(train_ds, list(range(10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76802f19-7b43-461c-b529-6547f0418bd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'small_train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43msmall_train_ds\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m      2\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(small_valid_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'small_train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(small_train_ds, batch_size=2, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(small_valid_ds, batch_size=2, shuffle=False, num_workers=0, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8eff67a-d2e6-469b-8463-4c58c98e3186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3, 256, 1600])\n",
      "Output shape: torch.Size([2, 4, 256, 1600])\n"
     ]
    }
   ],
   "source": [
    "model = UNetResNet18(num_classes=4, pretrained=False)\n",
    "\n",
    "x = torch.randn(2, 3, 256, 1600)  # batch size 2, 3-channel input\n",
    "y = model(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3be9f503-21ba-4e14-99f6-11576fe43bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import main\n",
    "\n",
    "# Test config ile sadece 2 epoch Ã§alÄ±ÅŸtÄ±ralÄ±m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed96e0f9-2f45-46de-8644-3172b681195c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'app/data/raw/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Kaggle'da train.csv yolunu ayarla\u001b[39;00m\n\u001b[1;32m      5\u001b[0m train_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp/data/raw/train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_csv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Class daÄŸÄ±lÄ±mÄ±\u001b[39;00m\n\u001b[1;32m      9\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msort_index()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'app/data/raw/train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Kaggle'da train.csv yolunu ayarla\n",
    "train_csv_path = \"app/data/raw/train.csv\"\n",
    "df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Class daÄŸÄ±lÄ±mÄ±\n",
    "class_counts = df[\"ClassId\"].value_counts().sort_index()\n",
    "\n",
    "print(\"ðŸ“Š SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Normalize edip yÃ¼zdelik gÃ¶sterelim\n",
    "print(\"\\nðŸ”Ž YÃ¼zdelik daÄŸÄ±lÄ±m:\")\n",
    "print(class_counts / class_counts.sum() * 100)\n",
    "\n",
    "# Ã‡izdir\n",
    "plt.figure(figsize=(6,4))\n",
    "class_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"Steel Defect Dataset - Class Distribution\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165b2b6-fefc-48c7-a1c9-f6406a827fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
